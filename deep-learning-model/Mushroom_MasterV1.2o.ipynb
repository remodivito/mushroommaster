{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ppREuCXXUUp"
   },
   "source": [
    "### V1.2o\n",
    "This notebook trains the model without utilising transfer learning - the model is purely trained on the mushroom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 50530,
     "status": "ok",
     "timestamp": 1744577591065,
     "user": {
      "displayName": "Remo Divito",
      "userId": "01700825693040477653"
     },
     "user_tz": -60
    },
    "id": "cmLLJkNu3ee5",
    "outputId": "5ee5e52c-a7c9-493b-fd93-ec0850d30816"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow --upgrade\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1aSueGfEHFVv"
   },
   "source": [
    "## Data Preparation\n",
    "Classes are moderately imbalanced due to the nature of the dataset (aggregated on mushroomobserver.com), so effort has to be made to be intentional in splitting samples from each class fairly. A 0.8/0.1/0.1 split has been chosen to begin with due to the dataset being quite small https://encord.com/blog/train-val-test-split/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3157908,
     "status": "ok",
     "timestamp": 1744580748976,
     "user": {
      "displayName": "Remo Divito",
      "userId": "01700825693040477653"
     },
     "user_tz": -60
    },
    "id": "zFukUL_7_8_z",
    "outputId": "eb2c189d-db59-4a8f-e157-dfe2f62c787c"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from google.cloud import storage\n",
    "from io import BytesIO\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "from google.colab import auth\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "auth.authenticate_user()\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "project_id = \"mushroom-master-136c0\"\n",
    "bucket_name = \"mushroom-master-central\"\n",
    "source_directory = \"cleaned_dataset/\"\n",
    "version = \"v1.2o\"\n",
    "\n",
    "client = storage.Client(project=project_id)\n",
    "bucket = client.bucket(bucket_name)\n",
    "\n",
    "!mkdir -p /content/local_data/cleaned_dataset\n",
    "!gsutil -m rsync -r gs://{bucket_name}/{source_directory} /content/local_data/cleaned_dataset\n",
    "\n",
    "local_data_dir = \"/content/local_data/cleaned_dataset\"\n",
    "\n",
    "def remove_hidden_files(folder_path):\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for d in dirs:\n",
    "            if d.startswith('.'):\n",
    "                shutil.rmtree(os.path.join(root, d))\n",
    "        for f in files:\n",
    "            if f.startswith('.'):\n",
    "                os.remove(os.path.join(root, f))\n",
    "\n",
    "def remove_corrupted_images(folder_path, valid_exts=(\".jpg\", \".jpeg\", \".png\")):\n",
    "    for ext in valid_exts:\n",
    "        pattern = os.path.join(folder_path, \"**\", f\"*{ext}\")\n",
    "        for file_path in glob.glob(pattern, recursive=True):\n",
    "            try:\n",
    "                with Image.open(file_path) as img:\n",
    "                    img.verify()\n",
    "                img = Image.open(file_path)\n",
    "                img.load()\n",
    "            except:\n",
    "                os.remove(file_path)\n",
    "\n",
    "def prune_empty_classes(folder_path, min_count=10):\n",
    "    for class_name in os.listdir(folder_path):\n",
    "        class_dir = os.path.join(folder_path, class_name)\n",
    "        if os.path.isdir(class_dir):\n",
    "            valid_images = [f for f in os.listdir(class_dir) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "            if len(valid_images) < min_count:\n",
    "                shutil.rmtree(class_dir)\n",
    "\n",
    "def get_images_and_labels_local(local_dir):\n",
    "    class_names = sorted([\n",
    "        d for d in os.listdir(local_dir) if os.path.isdir(os.path.join(local_dir, d)) and not d.startswith('.')\n",
    "    ])\n",
    "    class_to_index = {name: idx for idx, name in enumerate(class_names)}\n",
    "    paths = []\n",
    "    labels = []\n",
    "    for class_name in class_names:\n",
    "        class_path = os.path.join(local_dir, class_name)\n",
    "        for root, _, files in os.walk(class_path):\n",
    "            for f in files:\n",
    "                if f.lower().endswith((\".jpg\", \".jpeg\", \".png\")) and not f.startswith('.'):\n",
    "                    rel_path = os.path.join(os.path.relpath(root, local_dir), f)\n",
    "                    paths.append(rel_path)\n",
    "                    labels.append(class_to_index[class_name])\n",
    "    return np.array(paths), np.array(labels), class_names, class_to_index\n",
    "\n",
    "\n",
    "remove_hidden_files(local_data_dir)\n",
    "remove_corrupted_images(local_data_dir)\n",
    "prune_empty_classes(local_data_dir, min_count=1)\n",
    "\n",
    "all_image_paths, all_labels, class_names, class_to_index = get_images_and_labels_local(local_data_dir)\n",
    "num_classes = len(class_names)\n",
    "train_val_paths, test_paths, train_val_labels, test_labels = train_test_split(\n",
    "    all_image_paths, all_labels, test_size=0.1, stratify=all_labels, shuffle=True, random_state=42)\n",
    "\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    train_val_paths, train_val_labels, test_size=0.1, stratify=train_val_labels, random_state=42)\n",
    "\n",
    "batch_size = 128\n",
    "image_size = (224, 224)\n",
    "\n",
    "def parse_image(filename, label):\n",
    "    full_path = tf.strings.join([\"/content/local_data/cleaned_dataset/\", filename])\n",
    "    image_raw = tf.io.read_file(full_path)\n",
    "    image = tf.image.decode_jpeg(image_raw, channels=3)\n",
    "    image = tf.image.resize(image, image_size)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def create_dataset(paths, labels, shuffle=True, repeat=False):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(len(paths), seed=42)\n",
    "    if repeat:\n",
    "        ds = ds.repeat()\n",
    "    ds = ds.map(parse_image, num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds = create_dataset(train_paths, train_labels, shuffle=True, repeat=True)\n",
    "val_ds = create_dataset(val_paths, val_labels, shuffle=False)\n",
    "test_ds = create_dataset(test_paths, test_labels, shuffle=False)\n",
    "\n",
    "print(\"Train set:\", len(train_paths), \"Val set:\", len(val_paths), \"Test set:\", len(test_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8XN-uUuYsGAE"
   },
   "source": [
    "## Data Augmentation\n",
    "\n",
    "Data Augmentation is used to boost the size of the datasets to help account for the variability inherent in user-uploaded images. The imgaug library (https://imgaug.readthedocs.io/en/latest/) is used for its flexibility - moderately strong augmentations are performed, striking a balance between expanding the dataset and computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rJhL1YG0VFcV"
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "rotation_factor = 30 / 360.0\n",
    "zoom_factor = 0.2  # Scaling between 80% and 120%\n",
    "\n",
    "data_augmentation_layers = [\n",
    "    layers.RandomFlip(\"horizontal\"),  # Random horizontal flip (probability of 0.5)\n",
    "    layers.RandomRotation(factor=(-rotation_factor, rotation_factor)),  # Random rotation\n",
    "    layers.RandomZoom(height_factor=(-zoom_factor, zoom_factor), width_factor=(-zoom_factor, zoom_factor)),  # Random scaling\n",
    "]\n",
    "\n",
    "def data_augmentation(images, targets):\n",
    "    for layer in data_augmentation_layers:\n",
    "        images = layer(images)\n",
    "    # Clip values to ensure they remain in [0,1]\n",
    "    images = tf.clip_by_value(images, 0.0, 1.0)\n",
    "    return images, targets\n",
    "\n",
    "\n",
    "# Apply data augmentation to training dataset\n",
    "augmented_train_ds = train_ds.map(data_augmentation, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "augmented_train_ds = augmented_train_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hM-C5bbWeQiF"
   },
   "source": [
    "## Fine Tuning\n",
    "A fine-tuned version of the ConvNeXt-Base model - ConvNeXt is a CNN that implements characteristics of Visual Transformers to keep it comparable with state-of-the-art pure ViT architectures (https://arxiv.org/abs/2201.03545). The top 4 layers - the most abstract representations of the data - are then fine tuned and trained on the mushroom dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3417318,
     "status": "error",
     "timestamp": 1744600682428,
     "user": {
      "displayName": "Remo Divito",
      "userId": "01700825693040477653"
     },
     "user_tz": -60
    },
    "id": "yVRc-wnWIgLF",
    "outputId": "20d5331d-1c67-4b96-c510-918e57a930db"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import utils\n",
    "from keras.applications import ConvNeXtSmall\n",
    "import pickle\n",
    "\n",
    "model_path = f'/content/drive/MyDrive/mushroom_masterv1_ft{version}.keras'\n",
    "history_path = f'/content/drive/MyDrive/mushroom_training_history{version}.pkl'\n",
    "\n",
    "base_model = ConvNeXtSmall(\n",
    "    include_top=False,\n",
    "    weights=None,\n",
    "    input_shape=(224, 224, 3),\n",
    "    pooling='avg'\n",
    ")\n",
    "\n",
    "\n",
    "inputs= layers.Input(shape=(224, 224, 3))\n",
    "\n",
    "x = base_model(inputs)\n",
    "\n",
    "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001, clipnorm=1.0),\n",
    "    metrics=[\"accuracy\", tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5, name='top_5_accuracy')\n",
    "]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=8,\n",
    "    start_from_epoch=10,\n",
    "    min_delta=0.005,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr_plateau = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=4,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "steps_per_epoch = len(train_paths) // batch_size\n",
    "validation_steps = len(val_paths) // batch_size if len(val_paths) > batch_size else None\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=model_path,\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\"\n",
    "    ),\n",
    "    early_stopping,\n",
    "    reduce_lr_plateau\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    augmented_train_ds,\n",
    "    epochs=35,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_ds,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Save training history\n",
    "with open(history_path, 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "utils.plot_model(model, to_file='/content/drive/model_architecture.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2L_xUJ1Boen"
   },
   "source": [
    "# Display Data\n",
    "\n",
    "Display the model validation accuracy and loss at each epoch of the training cycle, and accuracy against test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 18069,
     "status": "ok",
     "timestamp": 1744726242251,
     "user": {
      "displayName": "Remo Divito",
      "userId": "01700825693040477653"
     },
     "user_tz": -60
    },
    "id": "FEDRF2fjULWZ",
    "outputId": "0a45124a-c523-47ec-af0b-4db11a7a5efe"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "!pip install tensorflow --upgrade\n",
    "import tensorflow as tf\n",
    "version = 'v1.2o'\n",
    "model_path = f'/content/drive/MyDrive/mushroom_masterv1_ft{version}.keras'\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "# test_loss, test_acc, test_top_5_acc = model.evaluate(test_ds, verbose=2)\n",
    "#print(f\"Test accuracy: {test_acc}, Test Top 5 Accuracy: {test_top_5_acc}\")\n",
    "\n",
    "import pickle\n",
    "history_path = f'/content/drive/MyDrive/mushroom_training_history{version}.pkl'\n",
    "with open(history_path, 'rb') as f:\n",
    "    history = pickle.load(f)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history['accuracy'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "plt.plot(history['top_5_accuracy'])\n",
    "plt.plot(history['val_top_5_accuracy'])\n",
    "\n",
    "#plt.plot([test_acc] * len(history['accuracy']), linestyle='--')  # Horizontal line for test accuracy\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation', 'Test', 'Top 5', 'Val Top 5'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "#plt.plot([test_loss] * len(history['loss']), linestyle='--')  # Horizontal line for test loss\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCAyW5BoBoen"
   },
   "source": [
    "# Convert to TFLite\n",
    "The trained model must be converted to a TFLite file to be compatible with the mobile app. From https://medium.com/@hellokhorshed/a-step-by-step-guide-to-convert-keras-model-to-tensorflow-lite-tflite-model-6c8d08707488"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "executionInfo": {
     "elapsed": 4500,
     "status": "error",
     "timestamp": 1744622815514,
     "user": {
      "displayName": "Remo Divito",
      "userId": "01700825693040477653"
     },
     "user_tz": -60
    },
    "id": "n2TI1pdZUWuo",
    "outputId": "5b21a3c0-7ee1-44ea-ec80-6b576fe71e5e"
   },
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model) #not doing this as the model underperformed\n",
    "tflite_model = converter.convert()\n",
    "with open(f'/content/drive/MyDrive/mushroom_master_mobile{version}.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19133,
     "status": "ok",
     "timestamp": 1744726224179,
     "user": {
      "displayName": "Remo Divito",
      "userId": "01700825693040477653"
     },
     "user_tz": -60
    },
    "id": "NHb5n6ksyRmu",
    "outputId": "61e30a78-868d-46dd-e675-e9284a0532b5"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
