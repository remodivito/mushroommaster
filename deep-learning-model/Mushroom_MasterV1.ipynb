{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1aSueGfEHFVv"
   },
   "source": [
    "## Data Preparation\n",
    "Classes are moderately imbalanced due to the nature of the dataset (aggregated on mushroomobserver.com), so effort has to be made to be intentional in splitting samples from each class fairly. A 0.8/0.1/0.1 split has been chosen to begin with due to the dataset being quite small https://encord.com/blog/train-val-test-split/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zFukUL_7_8_z",
    "outputId": "f64fcd3c-2247-4bb7-fc92-7f5f6b240528"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import logging\n",
    "\n",
    "source_directory = '/content/drive/Othercomputers/My MacBook Pro/MO_MI_images'\n",
    "version = 'v1'\n",
    "\n",
    "def is_valid_file(filepath):\n",
    "    \"\"\"Check if file is a valid image.\"\"\"\n",
    "    if not os.path.basename(filepath).startswith('.') and os.path.isfile(filepath):\n",
    "        try:\n",
    "            img = Image.open(filepath)\n",
    "            img.verify()\n",
    "            img.close()\n",
    "            return True\n",
    "        except (IOError, SyntaxError):\n",
    "            logging.warning(f\"Invalid image file: {filepath}\")\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def get_images_and_labels(source_dir, min_images_per_class=250):\n",
    "    class_names = [d for d in os.listdir(source_dir)\n",
    "                   if not d.startswith('.') and os.path.isdir(os.path.join(source_dir, d))]\n",
    "    class_names.sort()\n",
    "\n",
    "    # Filter classes based on minimum number of images\n",
    "    valid_class_names = []\n",
    "    class_to_image_paths = {}\n",
    "    for class_name in class_names:\n",
    "        class_dir = os.path.join(source_dir, class_name)\n",
    "        image_filenames = [f for f in os.listdir(class_dir)\n",
    "                           if is_valid_file(os.path.join(class_dir, f))]\n",
    "        if len(image_filenames) >= min_images_per_class: # this filters out most classes - will have to integrate more sources into dataset\n",
    "            valid_class_names.append(class_name)\n",
    "            image_paths = [os.path.join(class_dir, f) for f in image_filenames]\n",
    "            class_to_image_paths[class_name] = image_paths\n",
    "        else:\n",
    "            logging.warning(f\"Skipping class '{class_name}' (only {len(image_filenames)} images)\")\n",
    "\n",
    "    # Create a mapping from class names to label indices\n",
    "    class_names = sorted(valid_class_names)\n",
    "    class_to_index = {class_name: index for index, class_name in enumerate(class_names)}\n",
    "\n",
    "    # Collect all image paths and labels\n",
    "    all_image_paths = []\n",
    "    all_labels = []\n",
    "    for class_name in class_names:\n",
    "        image_paths = class_to_image_paths[class_name]\n",
    "        labels = [class_to_index[class_name]] * len(image_paths)\n",
    "        all_image_paths.extend(image_paths)\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "    return all_image_paths, all_labels, class_names, class_to_index\n",
    "\n",
    "all_image_paths, all_labels, class_names, class_to_index = get_images_and_labels(source_directory)\n",
    "num_classes = len(class_names)\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Total images: {len(all_image_paths)}\")\n",
    "\n",
    "# Save labels to a file\n",
    "with open(f'content/drive/MyDrive/labels{version}.txt', 'w') as f:\n",
    "    for label in class_names:\n",
    "        f.write(f\"{label}\\n\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert to numpy arrays\n",
    "all_image_paths = np.array(all_image_paths)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# First split into train/val and test\n",
    "train_val_paths, test_paths, train_val_labels, test_labels = train_test_split(\n",
    "    all_image_paths, all_labels, test_size=0.1, stratify=all_labels, random_state=42)\n",
    "\n",
    "# Then split train/val into train and val\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    train_val_paths, train_val_labels, test_size=0.1, stratify=train_val_labels, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {len(train_paths)}\")\n",
    "print(f\"Validation samples: {len(val_paths)}\")\n",
    "print(f\"Test samples: {len(test_paths)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EAxnVVtsH0cE"
   },
   "source": [
    "## Data Preprocessing\n",
    "Data needs to be:\n",
    "\n",
    "\n",
    "*   Decoded from JPEGs into RGB grids of pixels\n",
    "*   From there converted into floating-point tensors\n",
    "*   Reshaped into a standard size\n",
    "*   Packed into batches\n",
    "\n",
    "This can be done by the keras function `image_dataset_from_directory`. This function also features the ability to shuffle the training data to expose the model to a more diverse set of examples. (https://www.markovml.com/glossary/data-shuffling)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DD_sapIgH0mo"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 1536 # massive batch size to make use of 300GB RAM V28 TPU\n",
    "image_size = (224, 224)\n",
    "\n",
    "def load_and_preprocess_image(path, label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, image_size)\n",
    "    image = image / 255.0  # Normalize to [0,1] range\n",
    "    return image, label\n",
    "\n",
    "def create_dataset(image_paths, labels, shuffle=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(image_paths), seed=42)\n",
    "    dataset = dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "train_ds = create_dataset(train_paths, train_labels, shuffle=True)\n",
    "val_ds = create_dataset(val_paths, val_labels, shuffle=False)\n",
    "test_ds = create_dataset(test_paths, test_labels, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8XN-uUuYsGAE"
   },
   "source": [
    "## Data Augmentation\n",
    "\n",
    "Data Augmentation is used to boost the size of the datasets to help account for the variability inherent in user-uploaded images. The imgaug library (https://imgaug.readthedocs.io/en/latest/) is used for its flexibility - moderately strong augmentations are performed, striking a balance between expanding the dataset and computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6-_L2pQ2dp_H",
    "outputId": "2cfda4d5-0413-4248-e86f-cab1cabb7425"
   },
   "outputs": [],
   "source": [
    "!pip install keras-cv --upgrade\n",
    "import keras_cv\n",
    "import tensorflow as tf\n",
    "from keras_cv.layers import RandomApply\n",
    "from keras import layers\n",
    "\n",
    "rotation_factor = 30 / 360.0\n",
    "zoom_factor = 0.2  # Scaling between 80% and 120%\n",
    "\n",
    "data_augmentation_layers = [\n",
    "    layers.RandomFlip(\"horizontal\"),  # Random horizontal flip (probability of 0.5)\n",
    "    layers.RandomRotation(factor=(-rotation_factor, rotation_factor)),  # Random rotation\n",
    "    layers.RandomZoom(height_factor=(-zoom_factor, zoom_factor), width_factor=(-zoom_factor, zoom_factor)),  # Random scaling\n",
    "    RandomApply(\n",
    "        layer=keras_cv.layers.RandomGaussianBlur(kernel_size=3, factor=(0.0, 1.0)),\n",
    "        rate=0.5  # Apply with 50% probability\n",
    "    ),\n",
    "    keras_cv.layers.RandomBrightness(factor=(-0.3, 0.3)),  # Random brightness adjustment\n",
    "    RandomApply(\n",
    "        layer=keras_cv.layers.RandomCutout(\n",
    "            height_factor=(0.2, 0.2),\n",
    "            width_factor=(0.2, 0.2),\n",
    "        ),\n",
    "        rate=0.5\n",
    "    ),\n",
    "]\n",
    "\n",
    "def data_augmentation(images, targets):\n",
    "    for layer in data_augmentation_layers:\n",
    "        images = layer(images)\n",
    "    return images, targets\n",
    "\n",
    "# Apply data augmentation to training dataset\n",
    "augmented_train_ds = train_ds.map(data_augmentation, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "augmented_train_ds = augmented_train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hM-C5bbWeQiF"
   },
   "source": [
    "## Fine Tuning\n",
    "A fine-tuned version of the EfficientNetV2M - EfficientNetV2 shows both high efficiency (in terms of training time) and top-1 accuracy on the ImageNet benchmark (https://arxiv.org/pdf/2104.00298) and is very efficient in terms of training time. The 'M' (Medium) model is used to strike a balance between computational time and accuracy. The top 4 layers - the most abstract representations of the data - are then fine tuned and trained on the mushroom dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0SHkmd40dxEC",
    "outputId": "52d03267-d38f-43ae-e175-102ea9280eab"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.applications import EfficientNetV2M\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Define paths for saving model and history\n",
    "model_path = '/content/drive/MyDrive/mushroom_masterv1_ft.keras'\n",
    "history_path = '/content/drive/MyDrive/mushroom_training_history.pkl'\n",
    "\n",
    "try: # initialise TPU if it is not already intialised\n",
    "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(resolver)\n",
    "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "    strategy = tf.distribute.TPUStrategy(resolver)\n",
    "    print(\"TPU already initialized. Reusing existing TPU strategy.\")\n",
    "except ValueError:\n",
    "    print(\"TPU not initialized. Skipping TPU initialization.\")\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
    "\n",
    "with strategy.scope(): # within TPU strategy defined above\n",
    "    if os.path.exists(model_path):\n",
    "        # Load the model if it exists - saves recompiling it\n",
    "        model = keras.models.load_model(model_path)\n",
    "        print(\"Model loaded from disk.\")\n",
    "    else:\n",
    "        # Define and compile the model\n",
    "        base_model = EfficientNetV2M(\n",
    "            input_shape=(224, 224, 3),\n",
    "            weights=None,\n",
    "            include_top=True)\n",
    "\n",
    "        base_model.load_weights(\n",
    "            '/content/drive/MyDrive/efficientnetv2-m-21k.h5',\n",
    "            by_name=True, skip_mismatch=True)\n",
    "\n",
    "        base_model = keras.Model(\n",
    "            inputs=base_model.input,\n",
    "            outputs=base_model.get_layer(name='top_activation').output)\n",
    "\n",
    "        base_model.trainable = True\n",
    "        for layer in base_model.layers[:-4]:\n",
    "            layer.trainable = False\n",
    "\n",
    "        inputs = keras.Input(shape=(224, 224, 3))\n",
    "        x = base_model(inputs)\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        x = layers.Dense(256)(x)\n",
    "        x = layers.Dropout(0.25)(x)\n",
    "\n",
    "        outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "        model = keras.Model(inputs, outputs)\n",
    "\n",
    "        model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                      optimizer=keras.optimizers.Adam(learning_rate=1e-3), # https://arxiv.org/pdf/1412.6980 - may need to adjust LR\n",
    "                      metrics=[\"accuracy\"])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "# Early stopping callback - stops the model running unnecessarily\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint( # good if training stops unexpectedly\n",
    "        filepath=model_path,\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\"),\n",
    "    early_stopping\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=50,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Save the training history\n",
    "with open(history_path, 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D-QTuXSeXN-E"
   },
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "id": "1NAjR0VZXPnd",
    "outputId": "461b97fe-f6ed-465e-8aa5-dda8557a50ff"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "history_path = '/content/drive/MyDrive/mushroom_training_history.pkl'\n",
    "with open(history_path, 'rb') as f:\n",
    "    history = pickle.load(f)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history['accuracy'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
