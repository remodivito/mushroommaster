{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mushroom_master_local_gcs.py\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Requires:\n",
    "- google-cloud-storage\n",
    "- tensorflow, tensorflow_datasets, keras-cv\n",
    "- scikit-learn\n",
    "- matplotlib, pillow\n",
    "- gcloud authentication on your local machine\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.applications import ConvNeXtSmall\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For data augmentation\n",
    "import keras_cv\n",
    "from keras_cv.layers import RandomApply\n",
    "\n",
    "###############################################################################\n",
    "# 1. Load iNaturalist Data (mini) via TFDS (for pretraining).\n",
    "###############################################################################\n",
    "\n",
    "def preprocess_inat_data(image, label, img_size=(224, 224)):\n",
    "    image = tf.image.resize(image, img_size)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n",
    "\n",
    "print(\"Loading iNaturalist mini dataset...\")\n",
    "ds_inat_train, ds_inat_val = tfds.load(\n",
    "    \"i_naturalist2021_mini\",\n",
    "    split=[\"train[:90%]\", \"train[90%:]\"],\n",
    "    as_supervised=True\n",
    ")\n",
    "\n",
    "ds_inat_train = ds_inat_train.map(preprocess_inat_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_inat_val = ds_inat_val.map(preprocess_inat_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "ds_inat_train = ds_inat_train.batch(256).prefetch(tf.data.AUTOTUNE)\n",
    "ds_inat_val = ds_inat_val.batch(256).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# iNaturalist 2021 mini has 11083 classes\n",
    "num_inat_classes = 11083\n",
    "\n",
    "inat_base_model = ConvNeXtSmall(\n",
    "    input_shape=(224, 224, 3),\n",
    "    weights=None,\n",
    "    include_top=False\n",
    ")\n",
    "inat_base_model.trainable = True\n",
    "\n",
    "inputs_inat = layers.Input(shape=(224, 224, 3))\n",
    "x_inat = inat_base_model(inputs_inat)\n",
    "x_inat = layers.GlobalAveragePooling2D()(x_inat)\n",
    "outputs_inat = layers.Dense(num_inat_classes, activation='softmax')(x_inat)\n",
    "inat_model = tf.keras.Model(inputs_inat, outputs_inat)\n",
    "\n",
    "inat_model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\", tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5)]\n",
    ")\n",
    "\n",
    "print(\"Starting pretraining on iNaturalist (mini)...\")\n",
    "inat_model.fit(\n",
    "    ds_inat_train,\n",
    "    validation_data=ds_inat_val,\n",
    "    epochs=10  # Increase if you have time/resources\n",
    ")\n",
    "\n",
    "inat_checkpoint_path = \"./inat_pretrained_checkpoint.keras\"\n",
    "inat_model.save(inat_checkpoint_path)\n",
    "print(f\"Saved iNaturalist pretrained model to {inat_checkpoint_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 2. Read and organize the Mushroom data from GCS\n",
    "###############################################################################\n",
    "# We'll do the same approach: gather file paths from GCS, parse them by class,\n",
    "# split them into train/val/test sets with stratification, etc.\n",
    "\n",
    "# Adjust these to match your GCS environment\n",
    "bucket_name = \"mushroom-master-central\"           # e.g. \"my-bucket\"\n",
    "source_directory = \"cleaned_dataset\"              # e.g. \"cleaned_dataset\"\n",
    "gcs_prefix = f\"gs://{bucket_name}/{source_directory}\"\n",
    "\n",
    "# Remove hidden/corrupted images logic won't be the same on GCS as local,\n",
    "# but we can filter out obviously invalid paths or any non-image extension.\n",
    "\n",
    "def is_image_file(filename):\n",
    "    ext = filename.lower().rsplit('.', 1)[-1]\n",
    "    return ext in [\"jpg\", \"jpeg\", \"png\"]\n",
    "\n",
    "def list_gcs_files_recursive(prefix):\n",
    "    \"\"\"\n",
    "    Recursively list files under the given GCS prefix using tf.io.gfile.\n",
    "    Returns a list of all file paths that look like images.\n",
    "    \"\"\"\n",
    "    files = []\n",
    "    # tf.io.gfile.walk works similarly to os.walk, but for GCS\n",
    "    for (dirpath, dirnames, filenames) in tf.io.gfile.walk(prefix):\n",
    "        for fname in filenames:\n",
    "            full_path = os.path.join(dirpath, fname)\n",
    "            if is_image_file(full_path):\n",
    "                files.append(full_path)\n",
    "    return sorted(files)\n",
    "\n",
    "all_gcs_files = list_gcs_files_recursive(gcs_prefix)\n",
    "\n",
    "# We'll parse class names by splitting out the directory structure:\n",
    "# e.g. \"gs://bucket/cleaned_dataset/<class_name>/image.jpg\"\n",
    "# so we want the piece after \"cleaned_dataset/\" until the next slash as the class_name.\n",
    "\n",
    "def extract_class_name(file_path):\n",
    "    # Example path: \"gs://bucket/cleaned_dataset/<class_name>/image.jpg\"\n",
    "    # We want <class_name>\n",
    "    # We'll split by the source_directory + \"/\"\n",
    "    # then split by slash again\n",
    "    rel = file_path.split(source_directory + \"/\")[-1]\n",
    "    class_name = rel.split(\"/\")[0]\n",
    "    return class_name\n",
    "\n",
    "class_names = {}\n",
    "paths = []\n",
    "labels = []\n",
    "for fpath in all_gcs_files:\n",
    "    class_name = extract_class_name(fpath)\n",
    "    if class_name not in class_names:\n",
    "        class_names[class_name] = len(class_names)\n",
    "    class_idx = class_names[class_name]\n",
    "    paths.append(fpath)\n",
    "    labels.append(class_idx)\n",
    "\n",
    "paths = np.array(paths)\n",
    "labels = np.array(labels, dtype=int)\n",
    "unique_class_names = sorted(class_names.keys(), key=lambda x: class_names[x])\n",
    "num_classes = len(unique_class_names)\n",
    "\n",
    "# Now do train/test/val split with stratify\n",
    "train_val_paths, test_paths, train_val_labels, test_labels = train_test_split(\n",
    "    paths, labels, test_size=0.1, stratify=labels, shuffle=True, random_state=42)\n",
    "\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    train_val_paths, train_val_labels, test_size=0.1, stratify=train_val_labels, random_state=42)\n",
    "\n",
    "print(f\"Classes found: {num_classes}\")\n",
    "print(f\"Train set size: {len(train_paths)}\")\n",
    "print(f\"Val set size:   {len(val_paths)}\")\n",
    "print(f\"Test set size:  {len(test_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 3. Build tf.data.Dataset from GCS paths\n",
    "###############################################################################\n",
    "\n",
    "batch_size = 256\n",
    "image_size = (224, 224)\n",
    "\n",
    "def parse_gcs_image(file_path, label):\n",
    "    \"\"\"\n",
    "    Reads an image directly from GCS using tf.io.read_file, decodes, resizes, normalizes.\n",
    "    \"\"\"\n",
    "    image_raw = tf.io.read_file(file_path)\n",
    "    image = tf.image.decode_image(image_raw, channels=3, expand_animations=False)\n",
    "    image = tf.image.resize(image, image_size)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n",
    "\n",
    "def create_dataset(paths_arr, labels_arr, shuffle=True, repeat=False):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths_arr, labels_arr))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(len(paths_arr), seed=42)\n",
    "    if repeat:\n",
    "        ds = ds.repeat()\n",
    "    ds = ds.map(parse_gcs_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds = create_dataset(train_paths, train_labels, shuffle=True, repeat=True)\n",
    "val_ds = create_dataset(val_paths, val_labels, shuffle=False)\n",
    "test_ds = create_dataset(test_paths, test_labels, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 4. Data Augmentation for the Mushroom Dataset\n",
    "###############################################################################\n",
    "\n",
    "rotation_factor = 30 / 360.0\n",
    "zoom_factor = 0.2\n",
    "\n",
    "data_augmentation_layers = [\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(factor=(-rotation_factor, rotation_factor)),\n",
    "    layers.RandomZoom(height_factor=(-zoom_factor, zoom_factor), width_factor=(-zoom_factor, zoom_factor)),\n",
    "    keras_cv.layers.RandomBrightness(factor=(-0.3, 0.3)),\n",
    "]\n",
    "\n",
    "def data_augmentation(images, targets):\n",
    "    for layer in data_augmentation_layers:\n",
    "        images = layer(images)\n",
    "    images = tf.clip_by_value(images, 0.0, 1.0)\n",
    "    return images, targets\n",
    "\n",
    "augmented_train_ds = train_ds.map(data_augmentation, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "augmented_train_ds = augmented_train_ds.prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 5. Fine-Tuning on Mushroom Images\n",
    "###############################################################################\n",
    "\n",
    "# Reload the pretrained iNat model base\n",
    "print(f\"Loading iNaturalist pretrained model from {inat_checkpoint_path} ...\")\n",
    "inat_base_model = keras.models.load_model(inat_checkpoint_path)\n",
    "\n",
    "# Freeze all but top 4 layers\n",
    "for layer in inat_base_model.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Build final model for mushroom classification\n",
    "inputs_mushroom = layers.Input(shape=(224, 224, 3))\n",
    "x_mushroom = inat_base_model(inputs_mushroom)\n",
    "x_mushroom = layers.GlobalAveragePooling2D()(x_mushroom)\n",
    "outputs_mushroom = layers.Dense(num_classes, activation='softmax')(x_mushroom)\n",
    "model = tf.keras.Model(inputs_mushroom, outputs_mushroom)\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001, clipnorm=1.0),\n",
    "    metrics=[\"accuracy\", tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5)]\n",
    ")\n",
    "\n",
    "model_path = \"./mushroom_masterv1_ft.keras\"\n",
    "history_path = \"./mushroom_training_history.pkl\"\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=8,\n",
    "    start_from_epoch=10,\n",
    "    min_delta=0.005,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr_plateau = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=4,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "steps_per_epoch = len(train_paths) // batch_size\n",
    "validation_steps = len(val_paths) // batch_size if len(val_paths) > batch_size else None\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=model_path,\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\"\n",
    "    ),\n",
    "    early_stopping,\n",
    "    reduce_lr_plateau\n",
    "]\n",
    "\n",
    "print(\"Beginning fine-tuning on mushroom images...\")\n",
    "history_obj = model.fit(\n",
    "    augmented_train_ds,\n",
    "    epochs=150,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_ds,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Save training history\n",
    "with open(history_path, 'wb') as f:\n",
    "    pickle.dump(history_obj.history, f)\n",
    "print(f\"Training history saved to: {history_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 6. Evaluate on Test Set\n",
    "###############################################################################\n",
    "\n",
    "test_loss, test_acc, test_top_5_acc = model.evaluate(test_ds, verbose=2)\n",
    "print(f\"Test Loss: {test_loss:.4f} | Test Accuracy: {test_acc:.4f} | Top-5 Accuracy: {test_top_5_acc:.4f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 7. Plot Accuracy/Loss\n",
    "###############################################################################\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open(history_path, 'rb') as f:\n",
    "    history = pickle.load(f)\n",
    "\n",
    "plt.plot(history['accuracy'], label='Train Acc')\n",
    "plt.plot(history['val_accuracy'], label='Val Acc')\n",
    "plt.plot([test_acc]*len(history['accuracy']), linestyle='--', label='Test Acc')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history['loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Val Loss')\n",
    "plt.plot([test_loss]*len(history['loss']), linestyle='--', label='Test Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 8. Convert to TFLite\n",
    "###############################################################################\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "with open(\"./mushroom_master_mobile.tflite\", 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"TFLite model saved to mushroom_master_mobile.tflite\")\n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
